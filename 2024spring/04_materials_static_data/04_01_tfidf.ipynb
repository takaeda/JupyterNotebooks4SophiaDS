{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30287f5d-76da-45f2-8e03-e78e22d4f62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリのインストール\n",
    "!pip3 install janome # 日本語形態素解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d6e412-a3ef-4cff-b153-4fb2537156e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from janome.tokenizer import Tokenizer\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 日本語テキストのトークン化を行うTokenizerの設定\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"テキストをトークン化し、意味を持つ単語（名詞、動詞、形容詞）のみを抽出してリストとして返します。\"\"\"\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    return [token.surface for token in tokens if token.part_of_speech.split(',')[0] in ['名詞', '動詞', '形容詞']]\n",
    "\n",
    "# サンプルデータセットの定義\n",
    "documents = [\n",
    "    \"ディープラーニングは人工知能の一機能です\",\n",
    "    \"人工知能と機械学習はコンピュータサイエンスの一部です\",\n",
    "    \"ディープラーニングはほとんどのAIアプリケーションで使用されています\"\n",
    "]\n",
    "\n",
    "\n",
    "# TfidfVectorizerの初期化とパラメータ説明\n",
    "vectorizer = TfidfVectorizer(\n",
    "    tokenizer=tokenize,    # 文書をトークン化するための関数: 上で関数として定義\n",
    "    token_pattern=None     # 上のとおり、カスタムトークナイザを使用するのでtoken_patternは無効とする（このオプションを指定しないとwarningがでるので指定する)\n",
    ")\n",
    "\n",
    "# 文書のTF-IDFベクトルを計算\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# クエリの定義とTF-IDFベクトルの計算\n",
    "query = \"AIとディープラーニング\"\n",
    "query_tfidf = vectorizer.transform([query])\n",
    "\n",
    "# 文書間のコサイン類似度の計算\n",
    "cosine_similarities = cosine_similarity(query_tfidf, tfidf_matrix).flatten()\n",
    "\n",
    "#===============================================\n",
    "# 出力\n",
    "for i, doc in enumerate(documents):\n",
    "    tokens = tokenize(doc)\n",
    "    print(f\"対象文書{i}: {doc}\")\n",
    "    print(f\"\\t分かち書きの結果（トークン化） => {tokens}\\n\")\n",
    "\n",
    "print(f\"\\nクエリ文書: {query}\")\n",
    "query_tokens = tokenize(query)\n",
    "print(f\"\\t分かち書きの結果（トークン化） => {query_tokens}\\n\")\n",
    "\n",
    "print(\"==============================================================\")\n",
    "# 文書とクエリのTF-IDFベクトルをテーブル形式で表示\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"\\n対象文章のTF-IDF行列:\")\n",
    "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "display(df_tfidf)\n",
    "\n",
    "print(\"クエリのTF-IDF行列:\")\n",
    "query_vector_df = pd.DataFrame(query_tfidf.toarray(), columns=feature_names)\n",
    "display(query_vector_df)\n",
    "\n",
    "# 類似度結果の表示\n",
    "print(\"クエリ文書との類似文書とその類似度:\")\n",
    "similarity_df = pd.DataFrame({\n",
    "    'Document': documents,\n",
    "    'Similarity': cosine_similarities\n",
    "}).sort_values(by='Similarity', ascending=False)\n",
    "display(similarity_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
