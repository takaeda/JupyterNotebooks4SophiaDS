{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7b2c4e-6906-4457-b039-62a836a52246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install tensorflow\n",
    "#!pip install protobuf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89d61f6-de10-48ce-96f5-0dd399952cc8",
   "metadata": {},
   "source": [
    "# AIの中間層の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5be565-b8b9-415f-8839-f6d783c3350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1cb872-97bd-4d3f-979f-750feeb3e26f",
   "metadata": {},
   "source": [
    "## MNISTデータの読み込み\n",
    "\n",
    "embeddingsを取得するために、元データが必要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070d4e2c-8b08-4043-81a0-1fa0702a5a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNISTデータの読み込み\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# データの正規化\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# データの形状確認\n",
    "print(\"Training data shape:\", train_images.shape)\n",
    "print(\"Testing data shape:\", test_images.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8566f9fc-8896-422b-9a7c-b1c8f5ec4246",
   "metadata": {},
   "source": [
    "## モデルの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fcd61d-5c43-4aff-8e93-25dccebd393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの読み込み\n",
    "loaded_model = tf.keras.models.load_model('model.keras')  # または 'model.h5'\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b234a2-c9f8-418a-a941-f7a6b793e885",
   "metadata": {},
   "source": [
    "### このモデルでは、どのような文字の間違いが多いかを確認\n",
    "正しくモデルが読み込みていることの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e5da89-ff72-4392-8fa3-83343053214e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def display_predictions(model, input_data, true_labels):\n",
    "    # Model predictions\n",
    "    predictions = model.predict(input_data)\n",
    "    \n",
    "    # Get the indices of the predicted classes\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Initialize a dictionary to count mismatches\n",
    "    mismatches = Counter()\n",
    "    \n",
    "    # Display results\n",
    "    for i in range(len(true_labels)):\n",
    "        if true_labels[i] != predicted_labels[i]:\n",
    "            # Increment the count of the mismatched pair in the dictionary\n",
    "            mismatches[(true_labels[i], predicted_labels[i])] += 1\n",
    "    \n",
    "    # Display mismatched information in a sorted manner\n",
    "    for (actual, predicted), count in mismatches.most_common():\n",
    "        print(f\"Mismatched Pair: Actual Label {actual} | Predicted Label {predicted} | Count: {count}\")\n",
    "\n",
    "# Since this is a hypothetical code snippet, we need to mock the model's predict function and the data\n",
    "# to be able to run this function without errors.\n",
    "\n",
    "# Use the first 10 samples from the teacher data to display the prediction results\n",
    "sample_data = test_images\n",
    "sample_labels = test_labels\n",
    "\n",
    "# Now we can call the modified function\n",
    "display_predictions(loaded_model, sample_data, sample_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c3cbd6-97c8-4c5a-8437-23f54947f486",
   "metadata": {},
   "source": [
    "## 埋め込みembeddings (各層のベクトル)の取得\n",
    "### 各層のembeddings取得用関数定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc13ca42-af25-45a0-a3aa-8e958cef74a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddingsを取得する関数\n",
    "def get_embeddings_by_layer_name(model, input_data, layer_name):\n",
    "    intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "    embeddings = intermediate_layer_model.predict(input_data)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1c6d36-49f3-444b-9952-3ad3fd1ec5ac",
   "metadata": {},
   "source": [
    "### embeddingsの取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579b312e-b928-4f57-8fa2-c3deb4c561f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データのembeddings取得\n",
    "embeddings_train_dense_1 = get_embeddings_by_layer_name(loaded_model, train_images, 'dense_1')  # 第1のDense層の出力\n",
    "embeddings_train_dense_2 = get_embeddings_by_layer_name(loaded_model, train_images, 'dense_2')  # 第2のDense層の出力\n",
    "embeddings_train_output = get_embeddings_by_layer_name(loaded_model, train_images, 'output')  # 出力層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3420de-8285-48a8-8e87-22ee93131c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 検証データのembeddings取得\n",
    "embeddings_test_dense_1 = get_embeddings_by_layer_name(loaded_model, test_images, 'dense_1')  # 第1のDense層の出力\n",
    "embeddings_test_dense_2 = get_embeddings_by_layer_name(loaded_model, test_images, 'dense_2')  # 第2のDense層の出力\n",
    "embeddings_test_output = get_embeddings_by_layer_name(loaded_model, test_images, 'output')  # 出力層"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a94693b-6b29-4282-8459-b25b7790ab71",
   "metadata": {},
   "source": [
    "## toorPIAによる中間層のembeddingsの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b22a40-821a-4b48-a98e-2315cd3a04e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import toorpia.utils as tp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2a2136-9db9-461c-b1cb-abbc72e98b14",
   "metadata": {},
   "source": [
    "### 訓練データのembeddingsの解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8644ce-cc1c-4ac2-ac0a-a8281303d2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# toorpiaによるembeddingsの可視化\n",
    "\n",
    "common_options = {\n",
    "#    'item_normalization': True,\n",
    "#    'vector_normalization': True,\n",
    "    'randomSeed': 0,\n",
    "}\n",
    "\n",
    "# 各fit_transform関数に共通のオプションを適用する\n",
    "results_train_dense_1 = tp.fit_transform(embeddings_train_dense_1, working_dir='analysis_dense_1', **common_options)\n",
    "results_train_dense_2 = tp.fit_transform(embeddings_train_dense_2, working_dir='analysis_dense_2', **common_options)\n",
    "results_train_output = tp.fit_transform(embeddings_train_output, working_dir='analysis_output', **common_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28161d1e-5a2d-41cd-a9b7-6a32505f4968",
   "metadata": {},
   "source": [
    "### 検証データのembeddingsの解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786ee0b4-d6b0-4cbc-8702-d476e1394fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# toorpiaによるembeddingsの可視化\n",
    "results_test_dense_1 = tp.fit_transform(embeddings_test_dense_1, addplot=True, working_dir='analysis_dense_1', **common_options)\n",
    "results_test_dense_2 = tp.fit_transform(embeddings_test_dense_2, addplot=True, working_dir='analysis_dense_2', **common_options)\n",
    "results_test_output = tp.fit_transform(embeddings_test_output, addplot=True, working_dir='analysis_output', **common_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce3d9b8-7255-4d41-b24c-0fa74509f6cb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up the figure and axes for two side-by-side plots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 12))  # Set total figure size\n",
    "\n",
    "# Data and labels for the first plot (training)\n",
    "x_train, y_train = results_train_dense_1[:, 0], results_train_dense_1[:, 1]\n",
    "\n",
    "# Markers setup\n",
    "markers = ['o', 's', '^', 'v', '<', '>', 'p', '*', 'h', 'D']\n",
    "\n",
    "# First subplot (training data)\n",
    "for i in sorted(range(10), reverse=False):\n",
    "    idx = np.where(train_labels == i)\n",
    "    ax1.scatter(x_train[idx], y_train[idx], c=[plt.cm.jet(i/9)], marker=markers[i], label=str(i), alpha=0.2, s=10)\n",
    "\n",
    "ax1.set_xlim(-4, 4)\n",
    "ax1.set_ylim(-4, 4)\n",
    "ax1.set_aspect('equal')\n",
    "ax1.legend()\n",
    "ax1.set_title('Training Data')\n",
    "\n",
    "# Data and labels for the second plot (test)\n",
    "x_test, y_test = results_test_dense_1[:, 0], results_test_dense_1[:, 1]\n",
    "\n",
    "# Base scatter for the test data, using training data as the base\n",
    "ax2.scatter(x_train, y_train, label='base', c='lightgray', alpha=0.2, s=10)\n",
    "\n",
    "# Second subplot (test data)\n",
    "for i in sorted(range(10), reverse=False):\n",
    "    idx = np.where(test_labels[0:len(x_test)] == i)\n",
    "    #idx = np.where(train_labels[0:len(x_test)] == i)\n",
    "    ax2.scatter(x_test[idx], y_test[idx], c=[plt.cm.jet(i/9)], marker=markers[i], label=str(i), alpha=0.5, s=25)\n",
    "\n",
    "ax2.set_xlim(-4, 4)\n",
    "ax2.set_ylim(-4, 4)\n",
    "ax2.set_aspect('equal')\n",
    "ax2.legend()\n",
    "ax2.set_title('Test Data')\n",
    "\n",
    "# Show the combined plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e15c19-d392-482a-bb50-a6dcb520c66d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up the figure and axes for two side-by-side plots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 12))  # Set total figure size\n",
    "\n",
    "# Data and labels for the first plot (training)\n",
    "x_train, y_train = results_train_dense_2[:, 0], results_train_dense_2[:, 1]\n",
    "\n",
    "# Markers setup\n",
    "markers = ['o', 's', '^', 'v', '<', '>', 'p', '*', 'h', 'D']\n",
    "\n",
    "# First subplot (training data)\n",
    "for i in sorted(range(10), reverse=False):\n",
    "    idx = np.where(train_labels == i)\n",
    "    ax1.scatter(x_train[idx], y_train[idx], c=[plt.cm.jet(i/9)], marker=markers[i], label=str(i), alpha=0.2, s=10)\n",
    "\n",
    "ax1.set_xlim(-4, 4)\n",
    "ax1.set_ylim(-4, 4)\n",
    "ax1.set_aspect('equal')\n",
    "ax1.legend()\n",
    "ax1.set_title('Training Data')\n",
    "\n",
    "# Data and labels for the second plot (test)\n",
    "x_test, y_test = results_test_dense_2[:, 0], results_test_dense_2[:, 1]\n",
    "\n",
    "# Base scatter for the test data, using training data as the base\n",
    "ax2.scatter(x_train, y_train, label='base', c='lightgray', alpha=0.2, s=10)\n",
    "\n",
    "# Second subplot (test data)\n",
    "for i in sorted(range(10), reverse=False):\n",
    "    idx = np.where(test_labels[0:len(x_test)] == i)\n",
    "    ax2.scatter(x_test[idx], y_test[idx], c=[plt.cm.jet(i/9)], marker=markers[i], label=str(i), alpha=0.5, s=25)\n",
    "\n",
    "ax2.set_xlim(-4, 4)\n",
    "ax2.set_ylim(-4, 4)\n",
    "ax2.set_aspect('equal')\n",
    "ax2.legend()\n",
    "ax2.set_title('Test Data')\n",
    "\n",
    "# Show the combined plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bc7ae6-e895-401d-8e12-f87041a583f8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up the figure and axes for two side-by-side plots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 12))  # Set total figure size\n",
    "\n",
    "# Data and labels for the first plot (training)\n",
    "x_train, y_train = results_train_output[:, 0], results_train_output[:, 1]\n",
    "\n",
    "# Markers setup\n",
    "markers = ['o', 's', '^', 'v', '<', '>', 'p', '*', 'h', 'D']\n",
    "\n",
    "# First subplot (training data)\n",
    "for i in sorted(range(10), reverse=False):\n",
    "    idx = np.where(train_labels == i)\n",
    "    ax1.scatter(x_train[idx], y_train[idx], c=[plt.cm.jet(i/9)], marker=markers[i], label=str(i), alpha=0.2, s=10)\n",
    "\n",
    "ax1.set_xlim(-4, 4)\n",
    "ax1.set_ylim(-4, 4)\n",
    "ax1.set_aspect('equal')\n",
    "ax1.legend()\n",
    "ax1.set_title('Training Data')\n",
    "\n",
    "# Data and labels for the second plot (test)\n",
    "x_test, y_test = results_test_output[:, 0], results_test_output[:, 1]\n",
    "\n",
    "# Base scatter for the test data, using training data as the base\n",
    "ax2.scatter(x_train, y_train, label='base', c='lightgray', alpha=0.2, s=10)\n",
    "\n",
    "# Second subplot (test data)\n",
    "for i in sorted(range(10), reverse=False):\n",
    "    idx = np.where(test_labels[0:len(x_test)] == i)\n",
    "    ax2.scatter(x_test[idx], y_test[idx], c=[plt.cm.jet(i/9)], marker=markers[i], label=str(i), alpha=0.5, s=25)\n",
    "\n",
    "ax2.set_xlim(-4, 4)\n",
    "ax2.set_ylim(-4, 4)\n",
    "ax2.set_aspect('equal')\n",
    "ax2.legend()\n",
    "ax2.set_title('Test Data')\n",
    "\n",
    "# Show the combined plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
